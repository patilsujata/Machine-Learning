{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Analysis using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie-Review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pos</td>\n",
       "      <td>on june       a self taught   idealistic   ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pos</td>\n",
       "      <td>apparently   director tony kaye had a major b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pos</td>\n",
       "      <td>one of my colleagues was surprised when i tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pos</td>\n",
       "      <td>after bloody clashes and independence won   l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pos</td>\n",
       "      <td>the american action film has been slowly drow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   Pos   films adapted from comic books have had plent...\n",
       "1   Pos   every now and then a movie comes along from a...\n",
       "2   Pos   you ve got mail works alot better than it des...\n",
       "3   Pos      jaws   is a rare film that grabs your atte...\n",
       "4   Pos   moviemaking is a lot like being the general m...\n",
       "5   Pos   on june       a self taught   idealistic   ye...\n",
       "6   Pos   apparently   director tony kaye had a major b...\n",
       "7   Pos   one of my colleagues was surprised when i tol...\n",
       "8   Pos   after bloody clashes and independence won   l...\n",
       "9   Pos   the american action film has been slowly drow..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove number\n",
    "import re # import all Regular expression functions\n",
    "df['text']=[re.sub('\\d','', i)for i in df['text']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pos</td>\n",
       "      <td>on june       a self taught   idealistic   ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pos</td>\n",
       "      <td>apparently   director tony kaye had a major b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pos</td>\n",
       "      <td>one of my colleagues was surprised when i tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pos</td>\n",
       "      <td>after bloody clashes and independence won   l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pos</td>\n",
       "      <td>the american action film has been slowly drow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   Pos   films adapted from comic books have had plent...\n",
       "1   Pos   every now and then a movie comes along from a...\n",
       "2   Pos   you ve got mail works alot better than it des...\n",
       "3   Pos      jaws   is a rare film that grabs your atte...\n",
       "4   Pos   moviemaking is a lot like being the general m...\n",
       "5   Pos   on june       a self taught   idealistic   ye...\n",
       "6   Pos   apparently   director tony kaye had a major b...\n",
       "7   Pos   one of my colleagues was surprised when i tol...\n",
       "8   Pos   after bloody clashes and independence won   l...\n",
       "9   Pos   the american action film has been slowly drow..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace punctuations with a white space\n",
    "import string\n",
    "df['text']=[re.sub('[%s]' % re.escape(string.punctuation), ' ', i) for i in df['text']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=[i.lower() for i in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \n",
       "0  [films, adapted, from, comic, books, have, had...  \n",
       "1  [every, now, and, then, a, movie, comes, along...  \n",
       "2  [you, ve, got, mail, works, alot, better, than...  \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...  \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "import pandas as pd \n",
    "#Word Tokenization\n",
    "import nltk # import package for tokenization\n",
    "#nltk.download('punkt') # download all spporting function /files for NLTK package\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text_wt'] = [word_tokenize(i) for i in df['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "      <th>text_SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \\\n",
       "0  [films, adapted, from, comic, books, have, had...   \n",
       "1  [every, now, and, then, a, movie, comes, along...   \n",
       "2  [you, ve, got, mail, works, alot, better, than...   \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...   \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...   \n",
       "\n",
       "                                             text_SW  \n",
       "0  [films, adapted, comic, books, plenty, success...  \n",
       "1  [every, movie, comes, along, suspect, studio, ...  \n",
       "2  [got, mail, works, alot, better, deserves, ord...  \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...  \n",
       "4  [moviemaking, lot, like, general, manager, nfl...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show the stop words\n",
    "#nltk.download('stopwords') #download Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#Remove All Stop Word\n",
    "df['text_SW'] = [[i for i in j if not i in stop_words] for j in df['text_wt']]# remove the word which is aviable in stopword libr\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('tagsets')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('tagsets')\n",
    "#nltk.help.upenn_tagset()# tagset documentation\n",
    "#nltk.download('wordnet')\n",
    "from collections import defaultdict #Default Dictionary is imported from collections\n",
    "from nltk.corpus import wordnet as wn #the corpus reader wordnet is imported.\n",
    "from nltk.tag import pos_tag\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. \n",
    "#By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN) #Dictionary is created where pos_tag (first letter) are the key values \n",
    "tag_map['J'] = wn.ADJ                   #whose values are mapped with the value \n",
    "tag_map['V'] = wn.VERB                  #from wordnet dictionary. We have taken the only first letter as \n",
    "tag_map['R'] = wn.ADV\n",
    "# we will use it later in the loop.\n",
    "#tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wt</th>\n",
       "      <th>text_SW</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pos</td>\n",
       "      <td>films adapted from comic books have had plent...</td>\n",
       "      <td>[films, adapted, from, comic, books, have, had...</td>\n",
       "      <td>[films, adapted, comic, books, plenty, success...</td>\n",
       "      <td>[film, adapt, comic, book, plenty, success, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pos</td>\n",
       "      <td>every now and then a movie comes along from a...</td>\n",
       "      <td>[every, now, and, then, a, movie, comes, along...</td>\n",
       "      <td>[every, movie, comes, along, suspect, studio, ...</td>\n",
       "      <td>[every, movie, come, along, suspect, studio, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pos</td>\n",
       "      <td>you ve got mail works alot better than it des...</td>\n",
       "      <td>[you, ve, got, mail, works, alot, better, than...</td>\n",
       "      <td>[got, mail, works, alot, better, deserves, ord...</td>\n",
       "      <td>[get, mail, work, alot, good, deserves, order,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pos</td>\n",
       "      <td>jaws   is a rare film that grabs your atte...</td>\n",
       "      <td>[jaws, is, a, rare, film, that, grabs, your, a...</td>\n",
       "      <td>[jaws, rare, film, grabs, attention, shows, si...</td>\n",
       "      <td>[jaw, rare, film, grab, attention, show, singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pos</td>\n",
       "      <td>moviemaking is a lot like being the general m...</td>\n",
       "      <td>[moviemaking, is, a, lot, like, being, the, ge...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "      <td>[moviemaking, lot, like, general, manager, nfl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  \\\n",
       "0   Pos   films adapted from comic books have had plent...   \n",
       "1   Pos   every now and then a movie comes along from a...   \n",
       "2   Pos   you ve got mail works alot better than it des...   \n",
       "3   Pos      jaws   is a rare film that grabs your atte...   \n",
       "4   Pos   moviemaking is a lot like being the general m...   \n",
       "\n",
       "                                             text_wt  \\\n",
       "0  [films, adapted, from, comic, books, have, had...   \n",
       "1  [every, now, and, then, a, movie, comes, along...   \n",
       "2  [you, ve, got, mail, works, alot, better, than...   \n",
       "3  [jaws, is, a, rare, film, that, grabs, your, a...   \n",
       "4  [moviemaking, is, a, lot, like, being, the, ge...   \n",
       "\n",
       "                                             text_SW  \\\n",
       "0  [films, adapted, comic, books, plenty, success...   \n",
       "1  [every, movie, comes, along, suspect, studio, ...   \n",
       "2  [got, mail, works, alot, better, deserves, ord...   \n",
       "3  [jaws, rare, film, grabs, attention, shows, si...   \n",
       "4  [moviemaking, lot, like, general, manager, nfl...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [film, adapt, comic, book, plenty, success, wh...  \n",
       "1  [every, movie, come, along, suspect, studio, e...  \n",
       "2  [get, mail, work, alot, good, deserves, order,...  \n",
       "3  [jaw, rare, film, grab, attention, show, singl...  \n",
       "4  [moviemaking, lot, like, general, manager, nfl...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer \n",
    " # Initializing WordNetLemmatizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemma']=[[lemmatizer.lemmatize(word,tag_map[tag[0]]) for word ,tag in pos_tag(i)] for i in df['text_SW']] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['lemma2']= df['lemma'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    film adapt comic book plenty success whether s...\n",
       "1    every movie come along suspect studio every in...\n",
       "2    get mail work alot good deserves order make fi...\n",
       "3    jaw rare film grab attention show single image...\n",
       "4    moviemaking lot like general manager nfl team ...\n",
       "Name: lemma2, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma2'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer(max_features=5000)\n",
    "Tfidf= tf.fit_transform(df['lemma2']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abound</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaron  abandon   ability  able    aboard  abound  abraham  absence  \\\n",
       "0       0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "1       0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "2       0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "3       0.0      0.0  0.000000   0.0  0.036021     0.0      0.0      0.0   \n",
       "4       0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "...     ...      ...       ...   ...       ...     ...      ...      ...   \n",
       "1995    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "1996    0.0      0.0  0.039843   0.0  0.000000     0.0      0.0      0.0   \n",
       "1997    0.0      0.0  0.064450   0.0  0.000000     0.0      0.0      0.0   \n",
       "1998    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "1999    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0      0.0   \n",
       "\n",
       "      absent  absolute  ...  youth  zane  zany  zellweger  zero  zeta  zombie  \\\n",
       "0        0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1        0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "2        0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "3        0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "4        0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "...      ...       ...  ...    ...   ...   ...        ...   ...   ...     ...   \n",
       "1995     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1996     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1997     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1998     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1999     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "\n",
       "      zone  zoom  zwick  \n",
       "0      0.0   0.0    0.0  \n",
       "1      0.0   0.0    0.0  \n",
       "2      0.0   0.0    0.0  \n",
       "3      0.0   0.0    0.0  \n",
       "4      0.0   0.0    0.0  \n",
       "...    ...   ...    ...  \n",
       "1995   0.0   0.0    0.0  \n",
       "1996   0.0   0.0    0.0  \n",
       "1997   0.0   0.0    0.0  \n",
       "1998   0.0   0.0    0.0  \n",
       "1999   0.0   0.0    0.0  \n",
       "\n",
       "[2000 rows x 5000 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Tfidf, columns=tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "df['class2'] = Encoder.fit_transform(df['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(Tfidf,df['class2'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abound</th>\n",
       "      <th>abraham</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>...</th>\n",
       "      <th>youth</th>\n",
       "      <th>zane</th>\n",
       "      <th>zany</th>\n",
       "      <th>zellweger</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandon   ability  able    aboard  abound  abraham   absence  \\\n",
       "0    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0  0.000000   \n",
       "1    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0  0.000000   \n",
       "2    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0  0.000000   \n",
       "3    0.0      0.0  0.000000   0.0  0.000000     0.0      0.0  0.029282   \n",
       "4    0.0      0.0  0.045214   0.0  0.067821     0.0      0.0  0.000000   \n",
       "\n",
       "   absent  absolute  ...  youth  zane  zany  zellweger  zero  zeta  zombie  \\\n",
       "0     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "1     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "2     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "3     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "4     0.0       0.0  ...    0.0   0.0   0.0        0.0   0.0   0.0     0.0   \n",
       "\n",
       "   zone      zoom  zwick  \n",
       "0   0.0  0.057196    0.0  \n",
       "1   0.0  0.000000    0.0  \n",
       "2   0.0  0.000000    0.0  \n",
       "3   0.0  0.000000    0.0  \n",
       "4   0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Test_X, columns=tf.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  81.5 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",round(accuracy_score(predictions_NB, Test_Y)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.64 s\n",
      "Wall time: 425 ms\n",
      " ------ Confusion Matrix-----[TN FP  FN TP]\n",
      "[[169  27]\n",
      " [ 27 177]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       196\n",
      "           1       0.87      0.87      0.87       204\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.86      0.86      0.86       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "Logistic Regression Accuracy Score ->  86.5 %\n",
      "Logistic Regression Area under curve ->  0.86\n"
     ]
    }
   ],
   "source": [
    "# 1. import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# 2. instantiate a logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "# 3. train the model using X_train_dtm\n",
    "%time logreg.fit(Train_X, Train_Y)#4. make class predictions for Test_X\n",
    "predictions_log = logreg.predict(Test_X)\n",
    "\n",
    "print(\" ------ Confusion Matrix-----[TN FP  FN TP]\")\n",
    "\n",
    "print(metrics.confusion_matrix(predictions_log, Test_Y))\n",
    "print(metrics.classification_report(predictions_log, Test_Y))\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Logistic Regression Accuracy Score -> \",round(accuracy_score(predictions_log, Test_Y)*100,2),\"%\")\n",
    "print(\"Logistic Regression Area under curve -> \",round(metrics.roc_auc_score(predictions_log, Test_Y),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
